{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER as QA for ACE2005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе статьи `A Unified MRC Framework for Named Entity Recognition` (https://arxiv.org/abs/1910.11476) и их реализации `mrc-for-flat-nested-ner` (https://github.com/ShannonAI/mrc-for-flat-nested-ner), но при помощи `PyTorch` (https://pytorch.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная версия Jupyter Notebook для данных `Ace2005` с использованием `BertLarge`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных для ознакомления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные `Ace2005`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = json.load(open('datasets/ace2005/mrc-ner.train', encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на них:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': \"BEGALA Well , we ' ll debate that later on in the show .\", 'end_position': [3], 'entity_label': 'ORG', 'impossible': False, 'qas_id': '0.2', 'query': 'organization entities are limited to companies, corporations, agencies, institutions and other groups of people.', 'span_position': ['3;3'], 'start_position': [3]}\n"
     ]
    }
   ],
   "source": [
    "for data in all_data:\n",
    "    if data['start_position'] != []:\n",
    "        print(data)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': \"We ' ll have a couple of experts come out , so I ' ll withhold my comments until then .\",\n",
       " 'end_position': [],\n",
       " 'entity_label': 'WEA',\n",
       " 'impossible': True,\n",
       " 'qas_id': '1.7',\n",
       " 'query': 'weapon entities are limited to physical devices such as instruments for physically harming such as guns, arms and gunpowder.',\n",
       " 'span_position': [],\n",
       " 'start_position': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключаем библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YiFyaDQ6Wp1U"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "from collections import namedtuple\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from models.classifier import MultiNonLinearClassifier, SingleLinearClassifier\n",
    "from transformers import BertModel, BertPreTrainedModel, BertTokenizer\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from torch import Tensor\n",
    "from torch.nn.modules import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from torch.optim import SGD\n",
    "from metrics.functional.query_span_f1 import query_span_f1\n",
    "\n",
    "from datasets.mrc_ner_dataset import MRCNERDataset\n",
    "from datasets.truncate_dataset import TruncateDataset\n",
    "from datasets.collate_functions import collate_to_max_length\n",
    "from models.bert_query_ner import BertQueryNER\n",
    "from models.query_ner_config import BertQueryNerConfig\n",
    "from loss import *\n",
    "from utils.get_parser import get_parser\n",
    "from utils.radom_seed import set_random_seed\n",
    "import logging\n",
    "\n",
    "set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим саму модель, в данном случае в качестве feature extractor берется `BertLarge` (может браться другой), задаются три головы сети - `начальная позиция`, `конечная позиция`, `спан` -- которые будут предсказываться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2iGcMg_koXI"
   },
   "outputs": [],
   "source": [
    "class BertQueryNER(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertQueryNER, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert_large/')\n",
    "\n",
    "        self.start_outputs = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.end_outputs = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.span_embedding = MultiNonLinearClassifier(self.bert.config.hidden_size * 2, 1, 0.3)\n",
    "\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: bert input tokens, tensor of shape [seq_len]\n",
    "            token_type_ids: 0 for query, 1 for context, tensor of shape [seq_len]\n",
    "            attention_mask: attention mask, tensor of shape [seq_len]\n",
    "        Returns:\n",
    "            start_logits: start/non-start probs of shape [seq_len]\n",
    "            end_logits: end/non-end probs of shape [seq_len]\n",
    "            match_logits: start-end-match probs of shape [seq_len, 1]\n",
    "        \"\"\"\n",
    "        bert_outputs = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "\n",
    "        sequence_heatmap = bert_outputs[0]  # [batch, seq_len, hidden]\n",
    "        batch_size, seq_len, hid_size = sequence_heatmap.size()\n",
    "\n",
    "        start_logits = self.start_outputs(sequence_heatmap).squeeze(-1)  # [batch, seq_len, 1]\n",
    "        end_logits = self.end_outputs(sequence_heatmap).squeeze(-1)  # [batch, seq_len, 1]\n",
    "\n",
    "        # for every position $i$ in sequence, should concate $j$ to\n",
    "        # predict if $i$ and $j$ are start_pos and end_pos for an entity.\n",
    "        # [batch, seq_len, seq_len, hidden]\n",
    "        start_extend = sequence_heatmap.unsqueeze(2).expand(-1, -1, seq_len, -1)\n",
    "        # [batch, seq_len, seq_len, hidden]\n",
    "        end_extend = sequence_heatmap.unsqueeze(1).expand(-1, seq_len, -1, -1)\n",
    "        # [batch, seq_len, seq_len, hidden*2]\n",
    "        span_matrix = torch.cat([start_extend, end_extend], 3)\n",
    "        # [batch, seq_len, seq_len]\n",
    "        span_logits = self.span_embedding(span_matrix).squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits, span_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `dataloader`'а, используем `tokenizer_large` (можно другой):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rqbZefGToP-K"
   },
   "outputs": [],
   "source": [
    "def get_dataloader(data_dir, prefix=\"train\", limit: int = None) -> DataLoader:\n",
    "    \"\"\"get training dataloader\"\"\"\n",
    "    \"\"\"\n",
    "    load_mmap_dataset\n",
    "    \"\"\"\n",
    "    json_path = os.path.join(data_dir, f\"mrc-ner.{prefix}\")\n",
    "    dataset = MRCNERDataset(json_path=json_path,\n",
    "                            tokenizer= BertWordPieceTokenizer(BertTokenizer.from_pretrained('./tokenizer_large').vocab),\n",
    "                            max_length=128,\n",
    "                            is_chinese=False,\n",
    "                            pad_to_maxlen=False\n",
    "                            )\n",
    "\n",
    "    if limit is not None:\n",
    "        dataset = TruncateDataset(dataset, limit)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=16,\n",
    "        num_workers=16,\n",
    "        shuffle=True if prefix == \"train\" else False,\n",
    "        collate_fn=collate_to_max_length\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные уже через `dataloader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPOT3rE0pnHu",
    "outputId": "77926f82-19dc-4078-8ace-66a097d4b9df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/easemerova/.conda/envs/my_py/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'ace2005/'\n",
    "trainloader = get_dataloader(data_dir, 'train')\n",
    "devloader = get_dataloader(data_dir, 'dev')\n",
    "testloader = get_dataloader(data_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем веса, на основе статьи вес для спана берется в уменьшенном масштабе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUS1nN9qnHV-",
    "outputId": "0c460d58-85a4-4b97-e443-7a8d4b5d024a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47619047619047616 0.47619047619047616 0.047619047619047616\n"
     ]
    }
   ],
   "source": [
    "weight_start = 1\n",
    "weight_end = 1\n",
    "weight_span = 0.1\n",
    "weight_sum = weight_start + weight_end + weight_span\n",
    "weight_start = weight_start / weight_sum\n",
    "weight_end = weight_end / weight_sum\n",
    "weight_span = weight_span / weight_sum\n",
    "print(weight_start, weight_end, weight_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем модель и функцию потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6sp6IOdmOjn",
    "outputId": "44c693f7-81db-4085-8273-e60077c9abe3"
   },
   "outputs": [],
   "source": [
    "model = BertQueryNER().cuda()\n",
    "bce_loss = BCEWithLogitsLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем оптимизатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "d0UpoPAfnuC2"
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.01,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                  betas=(0.9, 0.98),  # according to RoBERTa paper\n",
    "                  lr=3e-5)\n",
    "t_total = (len(trainloader)) * 20\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=3e-5, pct_start=float(0/t_total),\n",
    "    final_div_factor=1e4,\n",
    "    total_steps=t_total, anneal_strategy='linear'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "E5r1oy0LoneC"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloder):\n",
    "    model.train()\n",
    "    mean_loss = 0\n",
    "    for k, batch in enumerate(tqdm(dataloder)):\n",
    "        tokens, token_type_ids, start_labels, end_labels, start_label_mask, end_label_mask, match_labels, sample_idx, label_idx = batch\n",
    "        attention_mask = (tokens != 0).long()\n",
    "        tokens, attention_mask, token_type_ids = tokens.cuda(), attention_mask.cuda(), token_type_ids.cuda()\n",
    "        start_logits, end_logits, span_logits = model(tokens, attention_mask, token_type_ids)\n",
    "        start_logits, end_logits, span_logits = start_logits.cpu(), end_logits.cpu(), span_logits.cpu()\n",
    "        batch_size, seq_len = start_logits.size()\n",
    "\n",
    "        start_float_label_mask = start_label_mask.view(-1).float()\n",
    "        end_float_label_mask = end_label_mask.view(-1).float()\n",
    "        match_label_row_mask = start_label_mask.bool().unsqueeze(-1).expand(-1, -1, seq_len)\n",
    "        match_label_col_mask = end_label_mask.bool().unsqueeze(-2).expand(-1, seq_len, -1)\n",
    "        match_label_mask = match_label_row_mask & match_label_col_mask\n",
    "        match_label_mask = torch.triu(match_label_mask, 0)  # start should be less equal to end\n",
    "\n",
    "        start_preds = start_logits > 0\n",
    "        end_preds = end_logits > 0\n",
    "\n",
    "        match_candidates = torch.logical_or(\n",
    "            (start_preds.unsqueeze(-1).expand(-1, -1, seq_len)\n",
    "              & end_preds.unsqueeze(-2).expand(-1, seq_len, -1)),\n",
    "            (start_labels.unsqueeze(-1).expand(-1, -1, seq_len)\n",
    "              & end_labels.unsqueeze(-2).expand(-1, seq_len, -1))\n",
    "        )\n",
    "        match_label_mask = match_label_mask & match_candidates\n",
    "        float_match_label_mask = match_label_mask.view(batch_size, -1).float()\n",
    "\n",
    "        start_loss = bce_loss(start_logits.view(-1), start_labels.view(-1).float())\n",
    "        start_loss = (start_loss * start_float_label_mask).sum() / start_float_label_mask.sum()\n",
    "        end_loss = bce_loss(end_logits.view(-1), end_labels.view(-1).float())\n",
    "        end_loss = (end_loss * end_float_label_mask).sum() / end_float_label_mask.sum()\n",
    "        match_loss = bce_loss(span_logits.view(batch_size, -1), match_labels.view(batch_size, -1).float())\n",
    "        match_loss = match_loss * float_match_label_mask\n",
    "        match_loss = match_loss.sum() / (float_match_label_mask.sum() + 1e-10)\n",
    "\n",
    "\n",
    "        total_loss = weight_start * start_loss + weight_end * end_loss + weight_span * match_loss\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        mean_loss += total_loss.item()\n",
    "        if k % 500 == 0 and k > 0:\n",
    "            print(mean_loss / 500)\n",
    "            mean_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для валидации с выводом `recall`, `precision` и `f1` для полученных спанов, а также их сохранение для каждой эпохи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XtuonDmXUXEe"
   },
   "outputs": [],
   "source": [
    "def val(model, dataloder, epoch):\n",
    "    model.eval()\n",
    "    output = []\n",
    "    for batch in tqdm(dataloder):\n",
    "        tokens, token_type_ids, start_labels, end_labels, start_label_mask, end_label_mask, match_labels, sample_idx, label_idx = batch\n",
    "        attention_mask = (tokens != 0).long()\n",
    "        tokens, attention_mask, token_type_ids = tokens.cuda(), attention_mask.cuda(), token_type_ids.cuda()\n",
    "        start_logits, end_logits, span_logits = model(tokens, attention_mask, token_type_ids)\n",
    "        start_logits, end_logits, span_logits = start_logits.cpu(), end_logits.cpu(), span_logits.cpu()\n",
    "        start_preds, end_preds = start_logits > 0, end_logits > 0\n",
    "        span_f1_stats = query_span_f1(start_preds=start_preds, end_preds=end_preds, match_logits=span_logits,\n",
    "                                      start_label_mask=start_label_mask, end_label_mask=end_label_mask,\n",
    "                                      match_labels=match_labels)\n",
    "        output.append(span_f1_stats)\n",
    "    all_counts = torch.stack(output).sum(0)\n",
    "    span_tp, span_fp, span_fn = all_counts\n",
    "    span_recall = span_tp / (span_tp + span_fn + 1e-10)\n",
    "    span_precision = span_tp / (span_tp + span_fp + 1e-10)\n",
    "    span_f1 = span_precision * span_recall * 2 / (span_recall + span_precision + 1e-10)\n",
    "    print(span_recall, span_precision, span_f1)\n",
    "    with open('./log.txt', 'a') as f:\n",
    "        f.write(str(epoch) + '\\n')\n",
    "        f.write(str(span_recall.item()) + ' ' + str(span_precision.item()) + ' ' + str(span_f1.item()) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем обучение с сохранением весов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4b165J-WEqO",
    "outputId": "7e37dd72-0b68-4fd6-bb4d-a9ea6954dd3b"
   },
   "outputs": [],
   "source": [
    "for i in range(12 * len(trainloader)):\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ps9EbmlgobiE",
    "outputId": "1dd6576f-7fd0-4b90-f047-c09579f9eda4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:53<19:07,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12858526457287373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:47<17:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.075910789469257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:36<11:44,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.061657362127676606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:29<08:20,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05112056450545788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:19<05:41,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04574927730485797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:07<01:33,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04551873746048659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:37<00:00,  2.16it/s]\n",
      "100%|██████████| 464/464 [00:53<00:00,  8.71it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6917) tensor(0.7556) tensor(0.7223)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:55<21:30,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03606189742870629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:49<17:17,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03181121840281412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:37<11:41,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049799949171952906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:24<08:31,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030978964817244558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:16<05:31,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03074457576707937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:06<01:18,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03055802345322445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:33<00:00,  2.17it/s]\n",
      "100%|██████████| 464/464 [00:53<00:00,  8.68it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7099) tensor(0.8597) tensor(0.7777)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:56<20:30,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022608816804597153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:45<15:47,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02286664771893993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:37<13:31,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023191756658721717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:29<09:48,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024187730440113228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:17<05:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02328848049606313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:07<01:27,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022608148890780284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:37<00:00,  2.16it/s]\n",
      "100%|██████████| 464/464 [00:52<00:00,  8.79it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7581) tensor(0.8365) tensor(0.7954)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:52<26:19,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01784350582587649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:42<15:39,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017986737339699174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:33<12:31,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018268012501648626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:23<08:29,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01976233862398658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:12<05:11,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01847411076858407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:02<01:26,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017393200945865828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:32<00:00,  2.17it/s]\n",
      "100%|██████████| 464/464 [00:53<00:00,  8.67it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8142) tensor(0.8091) tensor(0.8116)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:49<18:06,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016011687345482643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:40<16:25,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015342441417000374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:30<11:57,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014979549706156831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:24<08:59,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016763105851685396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:16<05:59,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015364996974851237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:06<01:38,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013775797555004828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:35<00:00,  2.16it/s]\n",
      "100%|██████████| 464/464 [00:53<00:00,  8.70it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7815) tensor(0.8451) tensor(0.8121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:52<20:09,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011875225371244595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:47<19:43,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011067986467969604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:33<13:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011468220981754712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:28<09:37,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012283691499389533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:20<06:53,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009944946995739883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:09<01:22,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012394545834191376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:39<00:00,  2.16it/s]\n",
      "100%|██████████| 464/464 [00:53<00:00,  8.61it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8277) tensor(0.8280) tensor(0.8279)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:49<21:15,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00912054906013509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:44<17:36,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008904309441681107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:34<13:26,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008617623055411968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:26<08:15,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00841231902621803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:18<05:28,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007972502143325982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:07<01:34,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008814028137698188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:34<00:00,  2.17it/s]\n",
      "100%|██████████| 464/464 [00:53<00:00,  8.71it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8429) tensor(0.8366) tensor(0.8397)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:53<24:44,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007156675949554483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:46<17:37,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007781360217326437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:37<11:40,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0072049033869261625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:28<08:21,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007768534375463787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:14<05:50,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006468321072254184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:04<01:28,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0066971955895060095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:32<00:00,  2.17it/s]\n",
      "100%|██████████| 464/464 [00:53<00:00,  8.67it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8502) tensor(0.8136) tensor(0.8315)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:57<21:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005555701369274175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:43<15:20,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005587242028788751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:31<14:28,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005305168127291836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:26<09:24,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0060723101334697275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:21<06:06,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0062871849885050325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:10<01:26,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006844878789943323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:39<00:00,  2.16it/s]\n",
      "100%|██████████| 464/464 [00:53<00:00,  8.67it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8521) tensor(0.8348) tensor(0.8434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:56<21:50,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004093723350764776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:47<16:15,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004911231752288586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:37<13:15,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004951428298409155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:27<10:02,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005247203349957999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:14<05:12,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004656592710765835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:04<01:33,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005232201359729515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:32<00:00,  2.17it/s]\n",
      "100%|██████████| 464/464 [00:53<00:00,  8.68it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8455) tensor(0.8324) tensor(0.8389)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:52<20:03,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004495534385561768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:41<15:06,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004730289321611053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:33<11:54,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003926033476853263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2001/3194 [15:26<09:29,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003665020250267844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2501/3194 [19:14<05:01,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034495801364973887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3001/3194 [23:07<01:22,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0031303183382024144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3194/3194 [24:35<00:00,  2.16it/s]\n",
      "100%|██████████| 464/464 [00:53<00:00,  8.72it/s]\n",
      "  0%|          | 0/3194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8521) tensor(0.8292) tensor(0.8405)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3194 [03:56<23:11,  1.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002992035857952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1001/3194 [07:49<18:11,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027949979454024287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1501/3194 [11:42<13:28,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0033511064438807806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1645/3194 [12:48<11:51,  2.18it/s]"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train(model, trainloader)\n",
    "    torch.save(model.state_dict(), 'weights/BertLargeAce2005/weight' + str(i) + '.pth')\n",
    "    val(model, testloader, i)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
